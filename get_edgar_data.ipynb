{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "from get_edgar_data import ParseXML\n",
    "import os\n",
    "import yfinance as yf\n",
    "from tqdm import tqdm\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn filings into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParseXML:\n",
    "    @staticmethod\n",
    "    def calc_transactionAmounts(xmlpath):\n",
    "        \"\"\"Calculate the total transaction amount in $ of a giving form 4 in XML\"\"\"\n",
    "        xml = ET.parse(xmlpath).getroot()\n",
    "        total = 0\n",
    "\n",
    "        if xml is None:\n",
    "            return total\n",
    "\n",
    "        nonDerivativeTransactions = xml.findall(\n",
    "            \"./nonDerivativeTable/nonDerivativeTransaction\"\n",
    "        )\n",
    "\n",
    "        for t in nonDerivativeTransactions:\n",
    "            # D for disposed or A for acquired\n",
    "            action = t.find(\n",
    "                \"./transactionAmounts/transactionAcquiredDisposedCode/value\"\n",
    "            ).text\n",
    "            # number of shares disposed/acquired\n",
    "            shares = t.find(\"./transactionAmounts/transactionShares/value\").text\n",
    "            # price\n",
    "            priceRaw = t.find(\"./transactionAmounts/transactionPricePerShare/value\")\n",
    "            price = 0 if priceRaw is None else priceRaw.text\n",
    "            # set prefix to -1 if derivatives were disposed. set prefix to 1 if derivates were acquired.\n",
    "            prefix = -1 if action == \"D\" else 1\n",
    "            # calculate transaction amount in $\n",
    "            amount = prefix * float(shares) * float(price)\n",
    "            total += amount\n",
    "\n",
    "        return round(total, 2)\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_transactionPricePerShare(xmlpath):\n",
    "        \"\"\"Calculate the avg transaction price per share in $ of a giving form 4 in XML\"\"\"\n",
    "        xml = ET.parse(xmlpath).getroot()\n",
    "        if xml is None:\n",
    "            return np.nan\n",
    "\n",
    "        nonDerivativeTransactions = xml.findall(\n",
    "            \"./nonDerivativeTable/nonDerivativeTransaction\"\n",
    "        )\n",
    "\n",
    "        prices = []\n",
    "        shares = []\n",
    "        for t in nonDerivativeTransactions:\n",
    "            action = t.find(\n",
    "                \"./transactionAmounts/transactionAcquiredDisposedCode/value\"\n",
    "            ).text\n",
    "            shareRaw = t.find(\"./transactionAmounts/transactionShares/value\").text\n",
    "            priceRaw = t.find(\"./transactionAmounts/transactionPricePerShare/value\")\n",
    "            if not priceRaw is None:\n",
    "                prices.append(float(priceRaw.text) * float(shareRaw))\n",
    "                shares.append(float(shareRaw))\n",
    "\n",
    "        if (len(prices) > 0) and (len(shares) >0) and (np.sum(shares)!=0):\n",
    "            return np.sum(prices) / np.sum(shares)\n",
    "        else:\n",
    "            return np.nan\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_transactionShares(xmlpath):\n",
    "        \"\"\"Calculate the avg transaction price per share in $ of a giving form 4 in XML\"\"\"\n",
    "        xml = ET.parse(xmlpath).getroot()\n",
    "\n",
    "        if xml is None:\n",
    "            return np.nan\n",
    "\n",
    "        nonDerivativeTransactions = xml.findall(\n",
    "            \"./nonDerivativeTable/nonDerivativeTransaction\"\n",
    "        )\n",
    "\n",
    "        shares = []\n",
    "        for t in nonDerivativeTransactions:\n",
    "            action = t.find(\n",
    "                \"./transactionAmounts/transactionAcquiredDisposedCode/value\"\n",
    "            ).text\n",
    "            shareRaw = t.find(\"./transactionAmounts/transactionShares/value\")\n",
    "            prefix = -1 if action == \"D\" else 1\n",
    "            if not shareRaw is None:\n",
    "                shares.append(prefix * float(shareRaw.text))\n",
    "\n",
    "        if len(shares) > 0:\n",
    "            return np.sum(shares)\n",
    "        else:\n",
    "            return np.nan\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_absTransactionShares(xmlpath):\n",
    "        \"\"\"Calculate the avg transaction price per share in $ of a giving form 4 in XML\"\"\"\n",
    "        xml = ET.parse(xmlpath).getroot()\n",
    "        if xml is None:\n",
    "            return np.nan\n",
    "\n",
    "        nonDerivativeTransactions = xml.findall(\n",
    "            \"./nonDerivativeTable/nonDerivativeTransaction\"\n",
    "        )\n",
    "\n",
    "        shares = []\n",
    "        for t in nonDerivativeTransactions:\n",
    "            shareRaw = t.find(\"./transactionAmounts/transactionShares/value\")\n",
    "            if not shareRaw is None:\n",
    "                shares.append(float(shareRaw.text))\n",
    "        if len(shares) > 0:\n",
    "            return np.sum(shares)\n",
    "        else:\n",
    "            return np.nan\n",
    "\n",
    "    @staticmethod\n",
    "    def get_transaction_date(xmlpath):\n",
    "        \"\"\"get the transaction date\"\"\"\n",
    "        xml = ET.parse(xmlpath).getroot()\n",
    "        if xml is None:\n",
    "            return np.nan\n",
    "\n",
    "        periodOfReport = xml.find(\n",
    "            \"./periodOfReport\"\n",
    "        )\n",
    "        return pd.Timestamp(periodOfReport.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_filed_date(filingDir):\n",
    "    \"\"\"\n",
    "    return format: str, 20180109\n",
    "    \"\"\"\n",
    "    import re\n",
    "    with open(filingDir + \"/full-submission.txt\", \"r\") as f:\n",
    "        content = f.read()\n",
    "    date = re.search(\"FILED AS OF DATE:[\\s]*[0-9]{8}\", content).group()[-8:]\n",
    "    return pd.Timestamp(date)\n",
    "\n",
    "filingDir = \"./sec-edgar-filings/AAP\\\\4\\\\0000921895-18-000108\"\n",
    "xmlpath = filingDir + \"/filing-details.xml\"\n",
    "date = ParseXML.get_transaction_date(xmlpath=xmlpath)\n",
    "datetime.datetime.strftime(date, \"%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get EDGAR stats for AAPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgarDir = \"./sec-edgar-filings/\"\n",
    "ticker = \"BIO\"\n",
    "filingsDir = edgarDir + \"/\" + ticker + \"/4/\"\n",
    "dates = []\n",
    "transactionPricePerShare = []\n",
    "transactionShares = []\n",
    "absTransactionShares = []\n",
    "transactionAmounts = []\n",
    "filingName = []\n",
    "for filingDir in os.listdir(filingsDir):\n",
    "    dates.append(get_filed_date(filingsDir + \"/\" + filingDir))\n",
    "    xmlpath = filingsDir + \"/\" + filingDir + \"/filing-details.xml\" \n",
    "    transactionPricePerShare.append(ParseXML.calc_transactionPricePerShare(xmlpath=xmlpath))\n",
    "    transactionShares.append(ParseXML.calc_transactionShares(xmlpath=xmlpath))\n",
    "    absTransactionShares.append(ParseXML.calc_absTransactionShares(xmlpath=xmlpath))\n",
    "    transactionAmounts.append(ParseXML.calc_transactionAmounts(xmlpath=xmlpath))\n",
    "    filingName.append(filingDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stock = pd.read_csv(f\"./stock_data/{ticker}.csv\", index_col=0)\n",
    "df_stock.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.DataFrame.from_dict({\n",
    "    \"date\": dates,\n",
    "    \"transactionPricePerShare\": transactionPricePerShare, \n",
    "    \"transactionShares\": transactionShares, \n",
    "    \"absTransactionShares\": absTransactionShares, \n",
    "    \"transactionAmounts\": transactionAmounts,\n",
    "    \"filingName\": filingName\n",
    "})\n",
    "df_data = df_data.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data.to_csv(f\"./edgar_data/{ticker}.csv\")\n",
    "df_stats = df_data.groupby(level=0).sum()\n",
    "df_stats['numTransactions'] = df_data.groupby(\"date\")['transactionAmounts'].count()\n",
    "# df_stats.to_csv(f\"./stock_edgar_stats/{ticker}.csv\")\n",
    "df_stats.index = df_stats.index.strftime('%Y-%m-%d')\n",
    "df_stock = pd.read_csv(f\"./stock_data/{ticker}.csv\", index_col=0)\n",
    "# df_stock.merge(df_stats, left_index=True, right_index=True, how='outer').to_csv(f\"./bt_stock_data/{ticker}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stock.dropna().loc['2018-01-02']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get EDGAR Stats for SP500 Constituent Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_bt_stock_data(ticker, edgarDir=\"./sec-edgar-filings/\", bt_stock_data_dir=\"./bt_stock_data/\", stock_edgar_stats_dir = \"\", forwardMode=False):\n",
    "    if not os.path.exists(bt_stock_data_dir):\n",
    "        os.makedirs(bt_stock_data_dir)\n",
    "    \n",
    "    valid_dates = pd.read_csv(\"./stock_data/AAL.csv\", index_col=0).index.unique()\n",
    "\n",
    "    filingsDir = edgarDir + \"/\" + ticker + \"/4/\"\n",
    "    dates = []\n",
    "    transactionPricePerShare = []\n",
    "    transactionShares = []\n",
    "    absTransactionShares = []\n",
    "    transactionAmounts = []\n",
    "    filingName = []\n",
    "    for filingDir in os.listdir(filingsDir):\n",
    "        if forwardMode != True:\n",
    "            date = get_filed_date(filingsDir + \"/\" + filingDir)\n",
    "        xmlpath = filingsDir + \"/\" + filingDir + \"/filing-details.xml\" \n",
    "        if os.path.exists(xmlpath):\n",
    "            if forwardMode == True:\n",
    "                date = ParseXML.get_transaction_date(xmlpath=xmlpath)\n",
    "            if datetime.datetime.strftime(date, \"%Y-%m-%d\") in valid_dates:\n",
    "                dates.append(date)\n",
    "                transactionPricePerShare.append(ParseXML.calc_transactionPricePerShare(xmlpath=xmlpath))\n",
    "                transactionShares.append(ParseXML.calc_transactionShares(xmlpath=xmlpath))\n",
    "                absTransactionShares.append(ParseXML.calc_absTransactionShares(xmlpath=xmlpath))\n",
    "                transactionAmounts.append(ParseXML.calc_transactionAmounts(xmlpath=xmlpath))\n",
    "                filingName.append(filingDir)\n",
    "\n",
    "    df_data = pd.DataFrame.from_dict({\n",
    "        \"date\": dates,\n",
    "        \"transactionPricePerShare\": transactionPricePerShare, \n",
    "        \"transactionShares\": transactionShares, \n",
    "        \"absTransactionShares\": absTransactionShares, \n",
    "        \"transactionAmounts\": transactionAmounts,\n",
    "        \"filingName\": filingName\n",
    "    })\n",
    "    df_data = df_data.set_index('date')\n",
    "\n",
    "    df_data.to_csv(f\"./edgar_data/{ticker}.csv\")\n",
    "    df_stats = df_data.groupby(level=0).sum()\n",
    "    df_stats['numTransactions'] = df_data.groupby(\"date\")['transactionAmounts'].count()\n",
    "    df_stats.to_csv(f\"./stock_edgar_stats/{ticker}.csv\")\n",
    "    df_stats.index = df_stats.index.strftime('%Y-%m-%d')\n",
    "\n",
    "    df_stock = pd.read_csv(f\"./stock_data/{ticker}.csv\", index_col=0)\n",
    "    df_stock.dropna(inplace=True)\n",
    "    df_stock.merge(df_stats, left_index=True, right_index=True, how='outer').to_csv(f\"./bt_stock_data/{ticker}.csv\")\n",
    "    df_stock = df_stock.merge(df_stats, left_index=True, right_index=True, how='outer')\n",
    "    df_stock.to_csv(f\"{bt_stock_data_dir}/{ticker}.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 182/485 [03:59<07:35,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRC [WinError 3] The system cannot find the path specified: './sec-edgar-filings//FRC/4/'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 193/485 [04:14<07:08,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNRC [WinError 3] The system cannot find the path specified: './sec-edgar-filings//GNRC/4/'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 312/485 [07:06<03:04,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEE 'Float64Index' object has no attribute 'strftime'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 390/485 [09:25<02:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBNY [WinError 3] The system cannot find the path specified: './sec-edgar-filings//SBNY/4/'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 473/485 [11:29<00:12,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTW [WinError 3] The system cannot find the path specified: './sec-edgar-filings//WTW/4/'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 475/485 [11:30<00:06,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WY Out of bounds nanosecond timestamp: 1-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 485/485 [11:47<00:00,  1.46s/it]\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(os.listdir(\"./stock_data/\")):\n",
    "    ticker = file[:-4]\n",
    "    try:\n",
    "        gen_bt_stock_data(ticker, bt_stock_data_dir=\"./bt_stock_data_forward/\", forwardMode=True)\n",
    "    except Exception as e:\n",
    "        print(ticker, e)\n",
    "#almost 20min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Cross-sectional stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(f\"./bt_stock_data/AAL.csv\", index_col=0)\n",
    "bad_tickers = []\n",
    "for file in tqdm(os.listdir(\"./bt_stock_data/\")):\n",
    "       df = pd.read_csv(f\"./bt_stock_data/{file}\", index_col=0)\n",
    "       if len(df.index) != len(df0.index):\n",
    "              bad_tickers.append(file[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(f\"./bt_stock_data/AAL.csv\", index_col=0)\n",
    "date_df_dict = {}\n",
    "for file in tqdm(os.listdir(\"./bt_stock_data/\")):\n",
    "    if file[:-4] in bad_tickers:\n",
    "        continue\n",
    "    df = pd.read_csv(f\"./bt_stock_data/{file}\", index_col=0)\n",
    "    for date in df0.index:\n",
    "        if date not in date_df_dict:\n",
    "            date_df_dict[date] = df.loc[date]\n",
    "        else:\n",
    "            date_df_dict[date] = pd.concat([date_df_dict[date], df.loc[date]],axis=1)\n",
    "for k,v in date_df_dict.items():\n",
    "    date_df_dict[k] = v.T.reset_index().set_index('ticker')\n",
    "    date_df_dict[k].drop(columns='index', inplace=True)\n",
    "    v.to_csv(f\"./bt_stock_data_crossection/{k}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1008/1008 [00:11<00:00, 91.12it/s]\n"
     ]
    }
   ],
   "source": [
    "date_df_dict = {}\n",
    "cols = [\"rank_transactionPricePerShare\", \"rank_transactionShares\", \"rank_absTransactionShares\", \"rank_transactionAmounts\", \"rank_numTransactions\"]\n",
    "prefix = \"sum_decen_\"\n",
    "tcols = [prefix + col for col in cols]\n",
    "for file in tqdm(os.listdir(\"./bt_stock_data_crossection1/\")):\n",
    "    date = file[:-4]\n",
    "    df = pd.read_csv(f\"./bt_stock_data_crossection1/{file}\", index_col=0)\n",
    "    for i in range(len(cols)):\n",
    "        df[tcols[i]] = np.nan \n",
    "        df[tcols[i]][~np.isnan(df[cols[i]])] = np.abs(df[cols[i]] - 0.5).sum()/2\n",
    "    date_df_dict[date] = df\n",
    "    df.to_csv(f\"./bt_stock_data_crossection2/{file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turn Crosssectional Fields into Time-Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['transactionPricePerShare', 'transactionShares', 'absTransactionShares', 'transactionAmounts', 'numTransactions']\n",
    "tcols = ['rank_transactionPricePerShare', 'rank_transactionShares', 'rank_absTransactionShares', 'rank_transactionAmounts', 'rank_numTransactions']\n",
    "for k,v in date_df_dict.items():\n",
    "    tmp = v[cols].rank(pct=True)\n",
    "    tmp.columns = tcols\n",
    "    tmp = pd.concat([v,tmp], axis=1)\n",
    "    tmp.to_csv(f\"./bt_stock_data_crossection1/{k}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1008/1008 [03:08<00:00,  5.36it/s]\n"
     ]
    }
   ],
   "source": [
    "ticker_df_dict = {}\n",
    "for k,v in tqdm(date_df_dict.items()):\n",
    "    for ticker in v.index:\n",
    "        if ticker not in ticker_df_dict:\n",
    "            tmp = v.loc[[ticker]]\n",
    "            tmp['date'] = k\n",
    "            ticker_df_dict[ticker] = tmp\n",
    "        else:\n",
    "            tmp = v.loc[[ticker]]\n",
    "            tmp['date'] = k\n",
    "            ticker_df_dict[ticker] = pd.concat([ticker_df_dict[ticker], tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in ticker_df_dict.items():\n",
    "    tmp = v.reset_index().set_index('date')\n",
    "    tmp.to_csv(f\"./bt_stock_data1/{k}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SP500 Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>267.839996</td>\n",
       "      <td>268.809998</td>\n",
       "      <td>267.399994</td>\n",
       "      <td>268.769989</td>\n",
       "      <td>247.899780</td>\n",
       "      <td>86655700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>268.959991</td>\n",
       "      <td>270.640015</td>\n",
       "      <td>268.959991</td>\n",
       "      <td>270.470001</td>\n",
       "      <td>249.467896</td>\n",
       "      <td>90070400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>271.200012</td>\n",
       "      <td>272.160004</td>\n",
       "      <td>270.540009</td>\n",
       "      <td>271.609985</td>\n",
       "      <td>250.519257</td>\n",
       "      <td>80636400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>272.510010</td>\n",
       "      <td>273.559998</td>\n",
       "      <td>271.950012</td>\n",
       "      <td>273.420013</td>\n",
       "      <td>252.188705</td>\n",
       "      <td>83524000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>273.309998</td>\n",
       "      <td>274.100006</td>\n",
       "      <td>272.980011</td>\n",
       "      <td>273.920013</td>\n",
       "      <td>252.649902</td>\n",
       "      <td>57319200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-27</th>\n",
       "      <td>472.059998</td>\n",
       "      <td>477.309998</td>\n",
       "      <td>472.010010</td>\n",
       "      <td>477.260010</td>\n",
       "      <td>471.797455</td>\n",
       "      <td>56808600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-28</th>\n",
       "      <td>477.720001</td>\n",
       "      <td>478.809998</td>\n",
       "      <td>476.059998</td>\n",
       "      <td>476.869995</td>\n",
       "      <td>471.411896</td>\n",
       "      <td>47274600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-29</th>\n",
       "      <td>476.980011</td>\n",
       "      <td>478.559998</td>\n",
       "      <td>475.920013</td>\n",
       "      <td>477.480011</td>\n",
       "      <td>472.014954</td>\n",
       "      <td>54503000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-30</th>\n",
       "      <td>477.929993</td>\n",
       "      <td>479.000000</td>\n",
       "      <td>475.670013</td>\n",
       "      <td>476.160004</td>\n",
       "      <td>470.710052</td>\n",
       "      <td>55329000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31</th>\n",
       "      <td>475.640015</td>\n",
       "      <td>476.859985</td>\n",
       "      <td>474.670013</td>\n",
       "      <td>474.959991</td>\n",
       "      <td>469.523804</td>\n",
       "      <td>65237400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1008 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2018-01-02  267.839996  268.809998  267.399994  268.769989  247.899780   \n",
       "2018-01-03  268.959991  270.640015  268.959991  270.470001  249.467896   \n",
       "2018-01-04  271.200012  272.160004  270.540009  271.609985  250.519257   \n",
       "2018-01-05  272.510010  273.559998  271.950012  273.420013  252.188705   \n",
       "2018-01-08  273.309998  274.100006  272.980011  273.920013  252.649902   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2021-12-27  472.059998  477.309998  472.010010  477.260010  471.797455   \n",
       "2021-12-28  477.720001  478.809998  476.059998  476.869995  471.411896   \n",
       "2021-12-29  476.980011  478.559998  475.920013  477.480011  472.014954   \n",
       "2021-12-30  477.929993  479.000000  475.670013  476.160004  470.710052   \n",
       "2021-12-31  475.640015  476.859985  474.670013  474.959991  469.523804   \n",
       "\n",
       "              Volume  \n",
       "Date                  \n",
       "2018-01-02  86655700  \n",
       "2018-01-03  90070400  \n",
       "2018-01-04  80636400  \n",
       "2018-01-05  83524000  \n",
       "2018-01-08  57319200  \n",
       "...              ...  \n",
       "2021-12-27  56808600  \n",
       "2021-12-28  47274600  \n",
       "2021-12-29  54503000  \n",
       "2021-12-30  55329000  \n",
       "2021-12-31  65237400  \n",
       "\n",
       "[1008 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spy_ohlc_df = yf.download('SPY', start='2018-01-02', end='2022-01-01')\n",
    "spy_ohlc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_ohlc_df['Close'].pct_change(1).to_csv(\"./sp500_beta.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
